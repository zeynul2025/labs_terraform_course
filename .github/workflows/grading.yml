name: Grade Terraform Lab

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - 'week-*/lab-*/student-work/**'

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  grade:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout student code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ">=1.9.0"
          terraform_wrapper: false

      - name: Setup Infracost
        uses: infracost/actions/setup@v2
        with:
          api-key: ${{ secrets.INFRACOST_API_KEY }}

      - name: Install grading tools
        run: |
          sudo apt-get update && sudo apt-get install -y jq

          # Install conftest for lab-specific policy checks
          CONFTEST_VERSION="0.46.0"
          curl -sL "https://github.com/open-policy-agent/conftest/releases/download/v${CONFTEST_VERSION}/conftest_${CONFTEST_VERSION}_Linux_x86_64.tar.gz" | tar xz
          sudo mv conftest /usr/local/bin/

          # Keep checkov as fallback for labs without custom policies
          pip3 install checkov

      - name: Determine lab directory
        id: lab-info
        run: |
          CHANGED_FILES=$(git diff --name-only ${{ github.event.pull_request.base.sha }} ${{ github.event.pull_request.head.sha }})
          LAB_DIR=$(echo "$CHANGED_FILES" | grep -oP 'week-\d+/lab-\d+' | head -1 || echo "")

          if [ -z "$LAB_DIR" ]; then
            echo "::error::Could not determine lab directory from changed files"
            exit 1
          fi

          WEEK=$(echo "$LAB_DIR" | grep -oP 'week-\K\d+')
          LAB=$(echo "$LAB_DIR" | grep -oP 'lab-\K\d+')

          echo "lab_dir=$LAB_DIR" >> $GITHUB_OUTPUT
          echo "week=$WEEK" >> $GITHUB_OUTPUT
          echo "lab=$LAB" >> $GITHUB_OUTPUT
          echo "work_dir=$LAB_DIR/student-work" >> $GITHUB_OUTPUT
          echo "validator_dir=$LAB_DIR/.validator" >> $GITHUB_OUTPUT

          echo "üìö Grading: Week $WEEK, Lab $LAB"
          echo "üìÅ Student work: $LAB_DIR/student-work"
          echo "üìã Validator: $LAB_DIR/.validator"

      - name: Check for grading script
        id: check-grader
        run: |
          GRADE_SCRIPT="${{ steps.lab-info.outputs.validator_dir }}/grade.sh"

          if [ -f "$GRADE_SCRIPT" ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Found grading script: $GRADE_SCRIPT"
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "::error::No grading script found at $GRADE_SCRIPT"
            exit 1
          fi

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Run lab-specific setup
        run: |
          SETUP_SCRIPT="${{ steps.lab-info.outputs.validator_dir }}/setup.sh"

          echo "üìÅ Current directory: $(pwd)"
          echo "üìÅ Looking for setup script at: $SETUP_SCRIPT"
          echo "üìÅ Validator dir contents:"
          ls -la "${{ steps.lab-info.outputs.validator_dir }}" || echo "Directory not found"

          if [ -f "$SETUP_SCRIPT" ]; then
            echo "üîß Running lab-specific setup..."
            chmod +x "$SETUP_SCRIPT"
            bash "$SETUP_SCRIPT"
          else
            echo "‚ÑπÔ∏è  No lab-specific setup script found (optional)"
          fi

          # Ensure SSH key exists for labs that need it (fallback)
          if [ ! -f ~/.ssh/wordpress-lab.pub ]; then
            echo "üìù Creating fallback SSH key pair for terraform..."
            mkdir -p ~/.ssh
            ssh-keygen -t rsa -b 4096 -f ~/.ssh/wordpress-lab -N "" -q
            echo "‚úÖ SSH key pair created as fallback"
          fi

          # Verify the setup worked
          echo "üìÅ Checking ~/.ssh directory:"
          ls -la ~/.ssh/ || echo "~/.ssh not found"

      - name: Initialize Terraform
        working-directory: ${{ steps.lab-info.outputs.work_dir }}
        run: terraform init

      - name: Generate Terraform plan
        id: plan
        continue-on-error: true
        working-directory: ${{ steps.lab-info.outputs.work_dir }}
        run: |
          RUNNER_IP=$(curl -s https://ifconfig.me)
          echo "üåê Using runner IP for validation: $RUNNER_IP"

          terraform plan -out=tfplan -no-color \
            -var="student_name=${{ github.event.pull_request.user.login }}" \
            -var="my_ip=${RUNNER_IP}/32" \
            2>&1 | tee /tmp/plan.txt

          if [ ${PIPESTATUS[0]} -eq 0 ]; then
            terraform show -json tfplan > /tmp/plan.json
            echo "status=pass" >> $GITHUB_OUTPUT
            echo "‚úÖ Terraform plan generated successfully"
          else
            echo "{}" > /tmp/plan.json
            echo "status=fail" >> $GITHUB_OUTPUT
            echo "::warning::Terraform plan failed"
          fi

      - name: Run Infracost
        continue-on-error: true
        working-directory: ${{ steps.lab-info.outputs.work_dir }}
        run: |
          infracost breakdown --path . --format json --out-file /tmp/infracost.json 2>/dev/null || echo '{"totalMonthlyCost": "0"}' > /tmp/infracost.json

      - name: Run policy checks (conftest/Rego)
        continue-on-error: true
        run: |
          POLICY_DIR="${{ steps.lab-info.outputs.validator_dir }}/policy"

          if [ -d "$POLICY_DIR" ] && [ "$(ls -A $POLICY_DIR 2>/dev/null)" ]; then
            echo "üìã Running lab-specific policy checks with conftest..."
            conftest test /tmp/plan.json --policy "$POLICY_DIR" --output json > /tmp/conftest.json 2>&1 || true

            # Convert conftest output to a format the grading script expects
            # conftest output: array of results with failures/warnings/successes
            cat /tmp/conftest.json | jq '{
              results: {
                passed_checks: [.[] | .successes[]? | {check_id: "POLICY", resource: .msg}],
                failed_checks: [.[] | .failures[]? | {check_id: "POLICY", resource: .msg}],
                warnings: [.[] | .warnings[]? | {check_id: "POLICY", resource: .msg}]
              }
            }' > /tmp/policy-results.json 2>/dev/null || echo '{"results": {"passed_checks": [], "failed_checks": [], "warnings": []}}' > /tmp/policy-results.json

            echo "‚úÖ Lab-specific policy checks complete"
            cat /tmp/conftest.json
          else
            echo "‚ÑπÔ∏è  No lab-specific policies found, running generic Checkov scan..."
            checkov -d "${{ steps.lab-info.outputs.work_dir }}" --framework terraform --output json --quiet > /tmp/policy-results.json 2>/dev/null || echo '{"results": {"passed_checks": [], "failed_checks": []}}' > /tmp/policy-results.json
          fi

      - name: Run grading script
        id: grade
        run: |
          GRADE_SCRIPT="${{ steps.lab-info.outputs.validator_dir }}/grade.sh"
          WORK_DIR="${{ steps.lab-info.outputs.work_dir }}"

          chmod +x "$GRADE_SCRIPT"

          echo "üéì Running grading script..."

          # Run grading script and capture JSON output
          # Uses policy-results.json (from conftest or checkov fallback)
          GRADE_JSON=$("$GRADE_SCRIPT" "$WORK_DIR" /tmp/plan.json /tmp/infracost.json /tmp/policy-results.json)

          # Save JSON for later steps
          echo "$GRADE_JSON" > /tmp/grading-results.json

          # Extract key values for GitHub outputs
          TOTAL_EARNED=$(echo "$GRADE_JSON" | jq -r '.total.earned')
          TOTAL_MAX=$(echo "$GRADE_JSON" | jq -r '.total.max')
          LETTER=$(echo "$GRADE_JSON" | jq -r '.letter_grade')

          echo "total_earned=$TOTAL_EARNED" >> $GITHUB_OUTPUT
          echo "total_max=$TOTAL_MAX" >> $GITHUB_OUTPUT
          echo "letter_grade=$LETTER" >> $GITHUB_OUTPUT

          # Extract category scores
          echo "code_quality=$(echo "$GRADE_JSON" | jq -r '.scores.code_quality.earned')" >> $GITHUB_OUTPUT
          echo "functionality=$(echo "$GRADE_JSON" | jq -r '.scores.functionality.earned')" >> $GITHUB_OUTPUT
          echo "cost_mgmt=$(echo "$GRADE_JSON" | jq -r '.scores.cost_management.earned')" >> $GITHUB_OUTPUT
          echo "security=$(echo "$GRADE_JSON" | jq -r '.scores.security.earned')" >> $GITHUB_OUTPUT
          echo "documentation=$(echo "$GRADE_JSON" | jq -r '.scores.documentation.earned')" >> $GITHUB_OUTPUT

          echo ""
          echo "üìä Grade Summary: $TOTAL_EARNED/$TOTAL_MAX ($LETTER)"

      - name: Generate grade report
        id: report
        if: always()
        run: |
          GRADE_JSON=$(cat /tmp/grading-results.json)
          CURRENT_DATE=$(date -u +"%Y-%m-%d %H:%M:%S UTC")

          # Extract values from JSON
          LAB_NAME=$(echo "$GRADE_JSON" | jq -r '.lab.name')
          TOTAL_EARNED=$(echo "$GRADE_JSON" | jq -r '.total.earned')
          TOTAL_MAX=$(echo "$GRADE_JSON" | jq -r '.total.max')
          LETTER=$(echo "$GRADE_JSON" | jq -r '.letter_grade')

          # Category scores
          CQ_EARNED=$(echo "$GRADE_JSON" | jq -r '.scores.code_quality.earned')
          CQ_MAX=$(echo "$GRADE_JSON" | jq -r '.scores.code_quality.max')
          FUNC_EARNED=$(echo "$GRADE_JSON" | jq -r '.scores.functionality.earned')
          FUNC_MAX=$(echo "$GRADE_JSON" | jq -r '.scores.functionality.max')
          COST_EARNED=$(echo "$GRADE_JSON" | jq -r '.scores.cost_management.earned')
          COST_MAX=$(echo "$GRADE_JSON" | jq -r '.scores.cost_management.max')
          SEC_EARNED=$(echo "$GRADE_JSON" | jq -r '.scores.security.earned')
          SEC_MAX=$(echo "$GRADE_JSON" | jq -r '.scores.security.max')
          DOC_EARNED=$(echo "$GRADE_JSON" | jq -r '.scores.documentation.earned')
          DOC_MAX=$(echo "$GRADE_JSON" | jq -r '.scores.documentation.max')

          # Generate check details for each category
          generate_checks() {
            local category=$1
            echo "$GRADE_JSON" | jq -r --arg cat "$category" '
              .checks[$cat][]? |
              "- **\(.name)** (\(.points)/\(.max_points)): " +
              (if .status == "pass" then "‚úÖ " elif .status == "partial" then "‚ö†Ô∏è " else "‚ùå " end) +
              .message
            '
          }

          # Get errors and warnings
          ERRORS=$(echo "$GRADE_JSON" | jq -r '.errors[]? // empty' | sed 's/^/- ‚ùå /')
          WARNINGS=$(echo "$GRADE_JSON" | jq -r '.warnings[]? // empty' | sed 's/^/- ‚ö†Ô∏è /')

          # Determine grade emoji
          if [ "$TOTAL_EARNED" -ge 90 ]; then
            GRADE_EMOJI="üéâ"
            GRADE_MSG="Excellent work! Your code meets all requirements."
          elif [ "$TOTAL_EARNED" -ge 80 ]; then
            GRADE_EMOJI="‚úÖ"
            GRADE_MSG="Good job! Review the feedback below to improve your score."
          elif [ "$TOTAL_EARNED" -ge 70 ]; then
            GRADE_EMOJI="üìù"
            GRADE_MSG="Satisfactory. Address the issues noted below."
          else
            GRADE_EMOJI="‚ö†Ô∏è"
            GRADE_MSG="Needs Improvement. Please fix the issues above and update your PR."
          fi

          cat > /tmp/report.md <<EOFMARKER
          # üéì Lab Grading Report

          **Student:** @${{ github.event.pull_request.user.login }}
          **Lab:** Week ${{ steps.lab-info.outputs.week }}, Lab ${{ steps.lab-info.outputs.lab }} - ${LAB_NAME}
          **Submitted:** ${{ github.event.pull_request.created_at }}
          **Graded:** ${CURRENT_DATE}

          ---

          ## üìä Final Grade: ${TOTAL_EARNED}/${TOTAL_MAX} (${LETTER})

          ${GRADE_EMOJI} **${GRADE_MSG}**

          ---

          ## üìã Detailed Breakdown

          ### Code Quality (${CQ_EARNED}/${CQ_MAX} points)
          $(generate_checks "code_quality")

          ### Functionality (${FUNC_EARNED}/${FUNC_MAX} points)
          $(generate_checks "functionality")

          ### Cost Management (${COST_EARNED}/${COST_MAX} points)
          $(generate_checks "cost_management")

          ### Security (${SEC_EARNED}/${SEC_MAX} points)
          $(generate_checks "security")

          ### Documentation (${DOC_EARNED}/${DOC_MAX} points)
          $(generate_checks "documentation")

          ---

          $(if [ -n "$ERRORS" ]; then echo "## ‚ùå Errors"; echo "$ERRORS"; echo ""; fi)
          $(if [ -n "$WARNINGS" ]; then echo "## ‚ö†Ô∏è Warnings"; echo "$WARNINGS"; echo ""; fi)

          ## üìù Next Steps

          $(if [ "$TOTAL_EARNED" -lt 70 ]; then cat <<NEXT
          ### To Improve Your Grade:
          1. Fix any failed checks listed above
          2. Push your changes to this PR
          3. The grading workflow will run automatically
          NEXT
          fi)

          ---

          ## üîó Artifacts
          - View the full workflow run: [Actions](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
          - Detailed results available in workflow artifacts

          ---

          <sub>ü§ñ Automated grading powered by GitHub Actions | Questions? Tag @${{ github.repository_owner }} in a comment</sub>
          EOFMARKER

          echo "‚úÖ Report generated"

      - name: Post grade as PR comment
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('/tmp/report.md', 'utf8');

            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('Lab Grading Report')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: report
              });
              console.log('‚úÖ Updated existing grade comment');
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: report
              });
              console.log('‚úÖ Posted new grade comment');
            }

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: grading-artifacts
          path: |
            /tmp/plan.json
            /tmp/plan.txt
            /tmp/infracost.json
            /tmp/conftest.json
            /tmp/policy-results.json
            /tmp/grading-results.json
          retention-days: 30

      - name: Set job status
        if: always()
        run: |
          TOTAL=${{ steps.grade.outputs.total_earned || 0 }}

          if [ "$TOTAL" -ge 70 ]; then
            echo "‚úÖ Grade: $TOTAL/100 - PASSING"
            exit 0
          else
            echo "‚ö†Ô∏è Grade: $TOTAL/100 - NEEDS IMPROVEMENT"
            exit 0
          fi
